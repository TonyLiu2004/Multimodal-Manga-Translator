{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa683204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from transformers import MarianMTModel, MarianTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af22f393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 258/258 [00:00<00:00, 1293.70it/s, Materializing param=model.shared.weight]                                  \n",
      "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.decoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.encoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# model = MarianMTModel.from_pretrained(model_name)\n",
    "# tokenizer.save_pretrained(\"./backend/models/Helsinki/tokenizer\")\n",
    "# model.save_pretrained(\"./backend/models/Helsinki/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64e507cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 254/254 [00:00<00:00, 1208.88it/s, Materializing param=model.shared.weight]                                  \n"
     ]
    }
   ],
   "source": [
    "tokenizer = MarianTokenizer.from_pretrained(\"./backend/models/Helsinki/tokenizer\")\n",
    "model = MarianMTModel.from_pretrained(\"./backend/models/Helsinki/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939da6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 33])\n",
      "['President Balctine, give me 101% of that, and if nothing happens...']\n"
     ]
    }
   ],
   "source": [
    "text = [\"발련타인 대통령. 그걸로 101%를 만어줘계··· 아무 일도 일어나지 않는다면 모든 결 플내줄 수 있어... 들어 백\"]\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=False)\n",
    "print(inputs[\"input_ids\"].shape)\n",
    "\n",
    "translated = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=200,\n",
    "    early_stopping=False\n",
    ")\n",
    "print(tokenizer.batch_decode(translated, skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
