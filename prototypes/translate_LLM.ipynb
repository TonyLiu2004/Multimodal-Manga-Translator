{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8531d7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "import re\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b468c934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 339/339 [00:00<00:00, 1138.28it/s, Materializing param=model.norm.weight]                              \n"
     ]
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\")\n",
    "# tokenizer.save_pretrained(\"../backend/models/Qwen/tokenizer\")\n",
    "# model.save_pretrained(\"../backend/models/Qwen/model\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../backend/models/Qwen/tokenizer\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"../backend/models/Qwen/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a845df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_with_llm(text):\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": \"\"\"\n",
    "            You are a professional Manga Localizer. You will receive JSON-formatted Japanese OCR text from the manga \"Naruto.\"\n",
    "\n",
    "            CRITICAL INSTRUCTIONS:\n",
    "\n",
    "            OUTPUT ONLY ENGLISH: Do not provide Romaji or Japanese in the final translation.\n",
    "\n",
    "            FIX OCR ERRORS: The input has errors (e.g., 'バー' might be 'バカ'). Use your knowledge of Naruto to correct them.\n",
    "\n",
    "            CONVINCING DIALOGUE: Use character-specific voices (e.g., Naruto's \"Believe it!\", Iruka's stern teacher tone).\n",
    "\n",
    "            MATCH IDs: Return the response as a JSON object matching the input IDs.\n",
    "\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": text\n",
    "    },\n",
    "    ]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=True,\n",
    "        return_dict=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    outputs = model.generate(**inputs, max_new_tokens=400)\n",
    "    output_text = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effcfd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_clean(json_str):\n",
    "    try:\n",
    "        # 1. Handle cases where the LLM adds \"Here is the JSON:\" text\n",
    "        match = re.search(r'\\[.*\\]', json_str, re.DOTALL)\n",
    "        if match:\n",
    "            clean_str = match.group(0)\n",
    "            data = ast.literal_eval(clean_str)\n",
    "\n",
    "        for item in data:\n",
    "            idx = item.get('id', 0)\n",
    "            text = item.get('text', '').replace('\\n', ' ').strip()\n",
    "            \n",
    "            print(f\"{idx}: {text}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse JSON: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1316c996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse JSON: Extra data: line 1 column 51 (char 50)\n"
     ]
    }
   ],
   "source": [
    "result = translate_with_llm(\"\"\"[\n",
    "    {'id': 0, 'text': 'バーうっせんだってばよ！！'}, \n",
    "    {'id': 1, 'text': 'お前ちさ！お前らさ！こんな卑劣なことできねーだろ！！'}, \n",
    "    {'id': 2, 'text': 'だがォレはできる！！オレはスゴイ！！'},\n",
    "    {'id': 3, 'text': 'おーおー ！やってくれとるのォあのバカ！'}, \n",
    "    {'id': 4, 'text': 'ん？'}, {'id': 5, 'text': 'ん？'}, \n",
    "    {'id': 6, 'text': '三代目申し訳ありません！'}, \n",
    "    {'id': 7, 'text': 'お！イルカか．．．'}, \n",
    "    {'id': 8, 'text': 'やべ！イルカ先生 だ'}, \n",
    "    {'id': 9, 'text': '何やってんだ授業中だぞ！早く降りてこい！！'}\n",
    "    ]\n",
    "\"\"\")\n",
    "parse_and_clean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "080aaa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bubble 0: Hey shut up already damn it!!\n",
      "Bubble 1: You brat! You guys! You can't do something so lowly!!\n",
      "Bubble 2: But I can do it!! I'm awesome!!\n",
      "Bubble 3: Oh oh! That's Naruto! That idiot is actually doing it!\n",
      "Bubble 4: Hm?\n",
      "Bubble 5: Hm?\n",
      "Bubble 6: Third Hokage, I apologize!\n",
      "Bubble 7: Ah! It's Iruka...\n",
      "Bubble 8: Shit! It's Iruka-sensei!\n",
      "Bubble 9: What are you doing? This is class time! Get down here right now!!\n"
     ]
    }
   ],
   "source": [
    "parse_and_clean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f884a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
