{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6514b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import io\n",
    "import re\n",
    "import textwrap\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bc1244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('best.pt')\n",
    "\n",
    "font = ImageFont.truetype(\n",
    "    \"./NotoSansCJK.ttc\",\n",
    "    size=12,\n",
    "    index=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d036efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_url = \"./test_images/test_3.png\"\n",
    "# results = model.predict(img_url)\n",
    "\n",
    "# results[0].save_crop(\"./bubble_test_results\") #save cropped bubbles\n",
    "# results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a047042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for box in results[0].boxes:\n",
    "#     # print(box)\n",
    "#     x1, y1, x2, y2 = box.xyxy[0].tolist()  # Convert to list\n",
    "#     print(box.conf)\n",
    "#     print(x1,y1,x2,y2)\n",
    "#     print(\"===================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca7bb994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 510/510 [00:00<00:00, 1216.07it/s, Materializing param=model.visual.post_layernorm.weight]                           \n"
     ]
    }
   ],
   "source": [
    "from backend.services.glmocr_service import OCR_Service\n",
    "from pathlib import Path\n",
    "base = Path.cwd()\n",
    "ocr_path = base / \"backend/models/GlmOcr\"\n",
    "ocr_service = OCR_Service(ocr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bea34e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_parameters` for 'rope_type'='dynamic': {'beta_fast', 'alpha', 'mscale', 'rope_theta', 'beta_slow', 'mscale_all_dim'}\n",
      "Loading weights: 100%|██████████| 355/355 [00:00<00:00, 1064.18it/s, Materializing param=model.norm.weight]                               \n",
      "The tied weights mapping and config for this model specifies to tie model.embed_tokens.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    }
   ],
   "source": [
    "from backend.services.tencentHY_service import Translate_Service\n",
    "\n",
    "translate_path = base / \"backend/models/TencentHY\" \n",
    "translate_service = Translate_Service(translate_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "843a282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_url = base / \"test_images\" / \"test_4.png\"\n",
    "# result = ocr_service.runOCR(img_url)\n",
    "# result = re.sub(r'[\\u2028\\u2029]+', ' ', result) #remove new line\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd9f1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_for_ocr(img, scale=2):\n",
    "    w, h = img.size\n",
    "    return img.resize((w*scale, h*scale), Image.BICUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a16df88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wrapped_text(text, font, max_width):\n",
    "    lines = []\n",
    "    words = text.split(' ') # Split by words for English\n",
    "    current_line = []\n",
    "\n",
    "    for word in words:\n",
    "        # Check if adding the next word exceeds the width\n",
    "        test_line = ' '.join(current_line + [word])\n",
    "        # getlength() is more accurate than getbbox for text width\n",
    "        if font.getlength(test_line) <= max_width:\n",
    "            current_line.append(word)\n",
    "        else:\n",
    "            lines.append(' '.join(current_line))\n",
    "            current_line = [word]\n",
    "    \n",
    "    lines.append(' '.join(current_line))\n",
    "    return lines\n",
    "\n",
    "def fit_text_to_box(draw, text, box_coords, font_path, initial_size=20):\n",
    "    x1, y1, x2, y2 = box_coords\n",
    "    target_width = x2 - x1\n",
    "    target_height = y2 - y1\n",
    "    \n",
    "    current_size = initial_size\n",
    "    lines = []\n",
    "    \n",
    "    # Loop to shrink font until it fits both width and height\n",
    "    while current_size > 8:\n",
    "        font = ImageFont.truetype(font_path, size=current_size)\n",
    "        lines = get_wrapped_text(text, font, target_width)\n",
    "        \n",
    "        # Calculate total height of the wrapped text block\n",
    "        line_height = font.getbbox(\"Ay\")[3] \n",
    "        total_height = line_height * len(lines)\n",
    "        \n",
    "        if total_height <= target_height:\n",
    "            break # It fits!\n",
    "        current_size -= 1 # Shrink and try again\n",
    "\n",
    "    return lines, font, current_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b43b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image_path, results, output_path=\"detected_manga.png\"):\n",
    "    # Load original image\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    i=0\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            # Get coordinates as a list of floats\n",
    "            coords = box.xyxy[0].tolist() # [x1, y1, x2, y2]\n",
    "            draw.rectangle(coords, outline=\"red\", width=1)\n",
    "            \n",
    "            # label\n",
    "            conf = box.conf[0].item()\n",
    "            box_cropped = img.crop(coords)\n",
    "            box_cropped = upscale_for_ocr(box_cropped, scale=3)\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".png\") as f:\n",
    "                box_cropped.save(f.name)      \n",
    "                temp_path = f.name\n",
    "\n",
    "\n",
    "            text = ocr_service.runOCR(temp_path) #OCR'd text\n",
    "            text = re.sub(r'[\\n\\r\\u2028\\u2029]+', ' ', text) #remove new lines\n",
    "            translated_text = translate_service.translate(text)\n",
    "            print(text)\n",
    "            print(translated_text)\n",
    "            print(\"====\")\n",
    "            # draw.text(\n",
    "            #     (coords[0], coords[1] - 10), \n",
    "            #     # f\"T=={conf:.2f}  {translated_text}\",\n",
    "            #     translated_text,  \n",
    "            #     fill=\"red\", \n",
    "            #     font=font\n",
    "            # )\n",
    "            # draw_wrapped_text(draw, translated_text, coords, font, fill=\"black\")\n",
    "\n",
    "            #wipe the space\n",
    "            draw.rectangle(coords, fill=\"white\", outline=\"white\")\n",
    "            # 1. Calculate the best fit\n",
    "            lines, best_font, final_size = fit_text_to_box(draw, translated_text, coords, \"./NotoSansCJK.ttc\")\n",
    "\n",
    "            # 2. Vertical Centering Logic\n",
    "            line_h = best_font.getbbox(\"Ay\")[3]\n",
    "            total_h = line_h * len(lines)\n",
    "            start_y = coords[1] + ( (coords[3] - coords[1]) - total_h ) / 2\n",
    "\n",
    "            # 3. Draw each line centered horizontally\n",
    "            for line in lines:\n",
    "                line = re.sub(r'[\\n\\r\\u2028\\u2029]+', ' ', line) #remove new lines\n",
    "                line_w = draw.textlength(line, font=best_font)\n",
    "                start_x = coords[0] + ( (coords[2] - coords[0]) - line_w ) / 2\n",
    "                draw.text((start_x, start_y), line, font=best_font, fill=\"black\")\n",
    "                start_y += line_h\n",
    "\n",
    "    img.save(output_path)\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "baa0c3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\tonyl\\Documents\\Multimodal-Manga-Translator\\test_images\\test_2.png: 1024x1280 15 texts, 128.4ms\n",
      "Speed: 7.3ms preprocess, 128.4ms inference, 0.2ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "明日は忍者学校の つつあげしけん 卒業試験だぞ!! 赤児かい お前は 前回もその前も しけん 試験に落ちてる!!\n",
      "Tomorrow is the graduation exam for the Ninja School! You're like a toddler, aren't you? You failed the ninja exams both times before!!\n",
      "====\n",
      "化 は る こと そ つ く り に\n",
      "The process of transformation is creating something new.\n",
      "====\n",
      "ねあく いもそ なし!! ろく\n",
      "Never mind, it's okay!! Six\n",
      "====\n",
      "ぜお前の さんぺん\n",
      "Your foolishness\n",
      "====\n",
      "今日の授業は 変化の術の 復習テストだ 全員 並べ\n",
      "Today’s class is a review test on the art of change. Everyone, line up!\n",
      "====\n",
      "外でいたすら してる場合じゃ ないだろ バカヤロ\n",
      "It's not the time to even think about helping others, idiot.\n",
      "====\n",
      "変化!!!\n",
      "Change!!!\n",
      "====\n",
      "O ㉑ ㉒ K ㉓ ㉔ ! ㉕\n",
      "You are a professional Manhua translator. This task requires translating dialogue from Chinese into natural, punchy English used in action manga. Please use slang appropriate for the genre, such as 'courting death', 'brat','senior'. The input may contain characters, punctuation, or sounds that don't make sense, so you should make educated guesses about the meaning of the sentences. If the input consists of a single character, simply return it as is without providing any translation. Do not respond with questions, commands, or anything else; only provide the translated text or leave it unchanged.\n",
      "====\n",
      "١٥-س١\n",
      "15-S1\n",
      "====\n",
      "22 22\n",
      "    22 22\n",
      "====\n",
      "次！ うずまぎナルト\n",
      "Next! Uzu Maji Naruto\n",
      "====\n",
      "知るかよ\n",
      "Do you even know?\n",
      "====\n",
      "えー！！！！\n",
      "Oh my god!!!!\n",
      "====\n",
      "7.7\n",
      "7.7\n",
      "====\n",
      "C\n",
      "You are a professional Manhua translator.  \n",
      "Translate the dialogue into natural, punchy English used in action manga.  \n",
      "Use genre-appropriate slang (e.g., 'courting death', 'brat','senior').  \n",
      "Sometimes the words you see may be incorrect; make assumptions about the sentence's meaning when necessary.  \n",
      "If the input consists of a single character, punctuation, or sounds like gibberish, simply return the input as it is, without any translation.  \n",
      "Do not answer questions, commands, or do anything else. You will only provide the translated text or nothing at all.  \n",
      "Do not output anything other than the translation.\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "img_url = \"./test_images/test_2.png\"\n",
    "results = model.predict(img_url)\n",
    "# results[0].save_crop(\"./bubble_test_results\") #save cropped bubbles\n",
    "draw_boxes(img_url, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8501b589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
